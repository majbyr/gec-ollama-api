HF_MODEL_NAME=tartuNLP/Llama-3.1-8B-est-gec-july-2025       # Error correction model
# HF_MODEL_NAME=tartuNLP/Llama-3.1-8B-est-ged-july-2025     # Error detection model
# HF_MODEL_NAME=tartuNLP/Llama-3.1-8B-est-gee-july-2025     # Error explanation model

# HF_TOKEN=your_huggingface_token_here 

# Model Configuration
MODEL_NAME=gec
# MODEL_NAME=ged
# MODEL_NAME=gee
QUANTIZATION=full

# Available quantization options:
# - full, orig: No quantization
# - f16, f32: Specific float precision
# - q2_k, q3_k_s, q3_k_m, q3_k_l, q4_0, q4_1, q4_k_s, q4_k_m, q5_0, q5_1, q5_k_s, q5_k_m, q6_k, q8_0: Quantized versions (smaller files, faster inference)

# API Configuration
OLLAMA_HOST=0.0.0.0
OLLAMA_ORIGINS=*
